<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Lip-Reading System - FYP</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            flex-direction: column;
        }

        .header {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            padding: 1rem 2rem;
            text-align: center;
            color: white;
            border-bottom: 1px solid rgba(255, 255, 255, 0.2);
        }

        .header h1 {
            font-size: 2.5rem;
            margin-bottom: 0.5rem;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
        }

        .header p {
            font-size: 1.1rem;
            opacity: 0.9;
        }

        .container {
            flex: 1;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 2rem;
        }

        .main-card {
            background: rgba(255, 255, 255, 0.95);
            border-radius: 20px;
            padding: 3rem;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.2);
            max-width: 800px;
            width: 100%;
            text-align: center;
        }

        .feature-tabs {
            display: flex;
            justify-content: center;
            margin-bottom: 2rem;
            border-radius: 10px;
            overflow: hidden;
            background: #f0f0f0;
        }

        .tab-button {
            flex: 1;
            padding: 1rem 2rem;
            background: #f0f0f0;
            border: none;
            cursor: pointer;
            font-size: 1rem;
            font-weight: 600;
            transition: all 0.3s ease;
            color: #666;
        }

        .tab-button.active {
            background: #667eea;
            color: white;
        }

        .tab-content {
            display: none;
            animation: fadeIn 0.5s ease-in-out;
        }

        .tab-content.active {
            display: block;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(20px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .video-container {
            position: relative;
            background: #000;
            border-radius: 15px;
            overflow: hidden;
            margin: 2rem 0;
            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.3);
        }

        #video-feed {
            width: 100%;
            height: 300px;
            object-fit: cover;
        }

        .controls {
            display: flex;
            justify-content: center;
            gap: 1rem;
            margin: 2rem 0;
            flex-wrap: wrap;
        }

        .btn {
            padding: 1rem 2rem;
            border: none;
            border-radius: 10px;
            font-size: 1rem;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            min-width: 120px;
        }

        .btn-primary {
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
        }

        .btn-primary:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.4);
        }

        .btn-secondary {
            background: #6c757d;
            color: white;
        }

        .btn-secondary:hover {
            background: #5a6268;
        }

        .btn-success {
            background: #28a745;
            color: white;
        }

        .btn-success:hover {
            background: #218838;
        }

        .file-input-wrapper {
            position: relative;
            overflow: hidden;
            display: inline-block;
        }

        .file-input {
            position: absolute;
            left: -9999px;
        }

        .results-section {
            margin-top: 2rem;
            padding: 2rem;
            background: linear-gradient(135deg, #f8f9fa, #e9ecef);
            border-radius: 15px;
            border-left: 5px solid #667eea;
        }

        .results-section h3 {
            color: #333;
            margin-bottom: 1rem;
            font-size: 1.5rem;
        }

        .transcription-output {
            background: white;
            padding: 1.5rem;
            border-radius: 10px;
            border: 2px solid #e9ecef;
            min-height: 80px;
            font-size: 1.2rem;
            font-weight: 600;
            color: #333;
            margin-bottom: 1rem;
            text-align: left;
        }

        .confidence-meter {
            display: flex;
            align-items: center;
            gap: 1rem;
            margin-top: 1rem;
        }

        .confidence-bar {
            flex: 1;
            height: 10px;
            background: #e9ecef;
            border-radius: 5px;
            overflow: hidden;
        }

        .confidence-fill {
            height: 100%;
            background: linear-gradient(90deg, #ff4757, #ffa502, #2ed573);
            width: 0%;
            transition: width 0.5s ease;
        }

        .status {
            padding: 1rem;
            border-radius: 10px;
            margin: 1rem 0;
            font-weight: 600;
        }

        .status.processing {
            background: #fff3cd;
            color: #856404;
            border: 1px solid #ffeaa7;
        }

        .status.success {
            background: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
        }

        .status.error {
            background: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
        }

        .upload-area {
            border: 3px dashed #667eea;
            border-radius: 15px;
            padding: 3rem;
            text-align: center;
            background: rgba(102, 126, 234, 0.05);
            transition: all 0.3s ease;
            cursor: pointer;
        }

        .upload-area:hover {
            background: rgba(102, 126, 234, 0.1);
            border-color: #764ba2;
        }

        .upload-area.dragover {
            background: rgba(102, 126, 234, 0.15);
            border-color: #764ba2;
            transform: scale(1.02);
        }

        .upload-icon {
            font-size: 3rem;
            color: #667eea;
            margin-bottom: 1rem;
        }

        .performance-stats {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 1rem;
            margin-top: 2rem;
        }

        .stat-card {
            background: white;
            padding: 1.5rem;
            border-radius: 10px;
            text-align: center;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
        }

        .stat-number {
            font-size: 2rem;
            font-weight: bold;
            color: #667eea;
            margin-bottom: 0.5rem;
        }

        .stat-label {
            color: #666;
            font-size: 0.9rem;
        }

        .footer {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            color: white;
            text-align: center;
            padding: 1rem;
            font-size: 0.9rem;
        }
    </style>
</head>
<body>
    <header class="header">
        <h1>AI Lip-Reading System</h1>
        <p>Deep Learning-Based Communication Assistance | Jimmy Yeow (TP068422) | APU FYP 2025</p>
    </header>

    <div class="container">
        <div class="main-card">
            <div class="feature-tabs">
                <button class="tab-button active" onclick="switchTab(event, 'live-tab')">Live Camera</button>
                <button class="tab-button" onclick="switchTab(event, 'upload-tab')">Upload Video</button>
                <button class="tab-button" onclick="switchTab(event, 'about-tab')">About System</button>
            </div>

            <!-- Live Camera Tab -->
            <div id="live-tab" class="tab-content active">
                <h2>Real-Time Lip Reading</h2>
                <p>Start your camera to begin live lip-reading transcription</p>
                
                <div class="video-container">
                    <video id="video-feed" autoplay muted></video>
                </div>

                <div class="controls">
                    <button class="btn btn-primary" onclick="startCamera()">Start Camera</button>
                    <button class="btn btn-secondary" onclick="stopCamera()">Stop Camera</button>
                    <button class="btn btn-success" onclick="startRecording()">Start Recording</button>
                    <button class="btn btn-secondary" onclick="stopRecording()">Stop & Process</button>
                </div>

                <div id="live-status" class="status" style="display: none;"></div>

                <div class="results-section">
                    <h3>Live Transcription</h3>
                    <div id="live-transcription" class="transcription-output">
                        Transcribed text will appear here in real-time...
                    </div>
                    <div class="confidence-meter">
                        <span>Confidence:</span>
                        <div class="confidence-bar">
                            <div id="live-confidence" class="confidence-fill"></div>
                        </div>
                        <span id="live-confidence-text">0%</span>
                    </div>
                </div>
            </div>

            <!-- Upload Video Tab -->
            <div id="upload-tab" class="tab-content">
                <h2>Upload Video for Processing</h2>
                <p>Upload a video file to get lip-reading transcription</p>

                <div class="upload-area" id="upload-area" onclick="document.getElementById('video-file').click()">
                    <div class="upload-icon">📹</div>
                    <h3>Drop video file here or click to browse</h3>
                    <p>Supported formats: MP4, AVI, MOV, WebM</p>
                    <input type="file" id="video-file" class="file-input" accept="video/*" onchange="handleFileUpload(event)">
                </div>

                <div class="controls">
                    <button class="btn btn-primary" onclick="processUploadedVideo()" id="process-btn" disabled>Process Video</button>
                    <button class="btn btn-secondary" onclick="clearUpload()">Clear</button>
                </div>

                <div id="upload-status" class="status" style="display: none;"></div>

                <div class="results-section">
                    <h3>Transcription Result</h3>
                    <div id="upload-transcription" class="transcription-output">
                        Upload and process a video to see transcription results...
                    </div>
                    <div class="confidence-meter">
                        <span>Confidence:</span>
                        <div class="confidence-bar">
                            <div id="upload-confidence" class="confidence-fill"></div>
                        </div>
                        <span id="upload-confidence-text">0%</span>
                    </div>
                </div>
            </div>

            <!-- About System Tab -->
            <div id="about-tab" class="tab-content">
                <h2>About This System</h2>
                <p>Transformer-based lip-reading system for hearing-impaired communication assistance</p>

                <div class="performance-stats">
                    <div class="stat-card">
                        <div class="stat-number">43.1%</div>
                        <div class="stat-label">Word Error Rate (WER)</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number">3,500</div>
                        <div class="stat-label">Training Samples</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number">21.5M</div>
                        <div class="stat-label">Model Parameters</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number">75fps</div>
                        <div class="stat-label">Processing Speed</div>
                    </div>
                </div>

                <div class="results-section">
                    <h3>Technical Architecture</h3>
                    <ul style="text-align: left; margin: 1rem 0;">
                        <li><strong>3D CNN Backbone:</strong> Spatial feature extraction from lip movements</li>
                        <li><strong>Transformer Encoder:</strong> 6 layers with 8 attention heads for temporal modeling</li>
                        <li><strong>CTC Decoding:</strong> Sequence-to-sequence alignment without forced alignment</li>
                        <li><strong>Multi-Dataset Training:</strong> GRID + MIRACL-VC1 for robust generalization</li>
                        <li><strong>Real-Time Processing:</strong> Optimized for live video inference</li>
                    </ul>

                    <h3>SDG Goal 10: Reduced Inequalities</h3>
                    <p style="text-align: left; margin: 1rem 0;">
                        This system supports hearing-impaired individuals by providing accessible communication tools,
                        reducing social barriers and promoting inclusive participation in education, work, and social activities.
                    </p>
                </div>
            </div>
        </div>
    </div>

    <footer class="footer">
        <p>&copy; 2025 Jimmy Yeow Kai Jim (TP068422) | Asia Pacific University | Final Year Project</p>
    </footer>

    <script>
        let mediaStream = null;
        let mediaRecorder = null;
        let recordedChunks = [];
        let uploadedFile = null;
    
        function switchTab(event, tabId) {
            const tabContents = document.querySelectorAll('.tab-content');
            tabContents.forEach(tab => tab.classList.remove('active'));
    
            const tabButtons = document.querySelectorAll('.tab-button');
            tabButtons.forEach(btn => btn.classList.remove('active'));
    
            document.getElementById(tabId).classList.add('active');
            event.target.classList.add('active');
        }
    
        async function startCamera() {
            try {
                mediaStream = await navigator.mediaDevices.getUserMedia({ 
                    video: { 
                        width: 640, 
                        height: 480,
                        facingMode: 'user'
                    } 
                });
                
                const videoElement = document.getElementById('video-feed');
                videoElement.srcObject = mediaStream;
                
                showStatus('live-status', 'Camera started successfully!', 'success');
            } catch (error) {
                showStatus('live-status', 'Error accessing camera: ' + error.message, 'error');
            }
        }
    
        function stopCamera() {
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
                
                const videoElement = document.getElementById('video-feed');
                videoElement.srcObject = null;
                
                showStatus('live-status', 'Camera stopped', 'success');
            }
        }
    
        function startRecording() {
            if (!mediaStream) {
                showStatus('live-status', 'Please start camera first', 'error');
                return;
            }
    
            recordedChunks = [];
            mediaRecorder = new MediaRecorder(mediaStream);
            
            mediaRecorder.ondataavailable = (event) => {
                if (event.data.size > 0) {
                    recordedChunks.push(event.data);
                }
            };
    
            mediaRecorder.onstop = () => {
                processRecordedVideo();
            };
    
            mediaRecorder.start();
            showStatus('live-status', 'Recording started...', 'processing');
        }
    
        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
                showStatus('live-status', 'Processing recorded video...', 'processing');
            }
        }
    
        async function processRecordedVideo() {
            try {
                const blob = new Blob(recordedChunks, { type: 'video/webm' });
                const formData = new FormData();
                formData.append('video', blob, 'recorded_video.webm');
    
                const response = await fetch('http://localhost:5000/api/process-video', {
                    method: 'POST',
                    body: formData
                });
    
                const result = await response.json();
                
                if (result.success) {
                    document.getElementById('live-transcription').textContent = result.transcription;
                    updateConfidence('live-confidence', 'live-confidence-text', result.confidence);
                    showStatus('live-status', 'Video processed successfully!', 'success');
                } else {
                    showStatus('live-status', 'Error processing video: ' + result.error, 'error');
                }
            } catch (error) {
                showStatus('live-status', 'Error processing video: ' + error.message, 'error');
            }
        }
    
        function handleFileUpload(event) {
            const file = event.target.files[0];
            if (file) {
                uploadedFile = file;
                document.getElementById('process-btn').disabled = false;
                showStatus('upload-status', 'File selected: ' + file.name, 'success');
            }
        }
    
        async function processUploadedVideo() {
            if (!uploadedFile) {
                showStatus('upload-status', 'Please select a video file first', 'error');
                return;
            }
    
            showStatus('upload-status', 'Processing video with AI model...', 'processing');
    
            try {
                const formData = new FormData();
                formData.append('video', uploadedFile);
    
                const response = await fetch('http://localhost:5000/api/process-video', {
                    method: 'POST',
                    body: formData
                });
    
                const result = await response.json();
                
                if (result.success) {
                    document.getElementById('upload-transcription').textContent = result.transcription;
                    updateConfidence('upload-confidence', 'upload-confidence-text', result.confidence);
                    showStatus('upload-status', 'Video processed successfully! Confidence: ' + Math.round(result.confidence * 100) + '%', 'success');
                } else {
                    showStatus('upload-status', 'Error processing video: ' + result.error, 'error');
                }
            } catch (error) {
                showStatus('upload-status', 'Error processing video: ' + error.message, 'error');
            }
        }
    
        function clearUpload() {
            uploadedFile = null;
            document.getElementById('video-file').value = '';
            document.getElementById('process-btn').disabled = true;
            document.getElementById('upload-transcription').textContent = 'Upload and process a video to see transcription results...';
            updateConfidence('upload-confidence', 'upload-confidence-text', 0);
            showStatus('upload-status', 'Upload cleared', 'success');
        }
    
        function showStatus(elementId, message, type) {
            const statusElement = document.getElementById(elementId);
            statusElement.textContent = message;
            statusElement.className = 'status ' + type;
            statusElement.style.display = 'block';
    
            if (type === 'success') {
                setTimeout(() => {
                    statusElement.style.display = 'none';
                }, 3000);
            }
        }
    
        function updateConfidence(barId, textId, confidence) {
            const confidenceBar = document.getElementById(barId);
            const confidenceText = document.getElementById(textId);
            
            const percentage = Math.round(confidence * 100);
            confidenceBar.style.width = percentage + '%';
            confidenceText.textContent = percentage + '%';
        }
    
        // Drag and drop functionality
        const uploadArea = document.getElementById('upload-area');
    
        uploadArea.addEventListener('dragover', (e) => {
            e.preventDefault();
            uploadArea.classList.add('dragover');
        });
    
        uploadArea.addEventListener('dragleave', () => {
            uploadArea.classList.remove('dragover');
        });
    
        uploadArea.addEventListener('drop', (e) => {
            e.preventDefault();
            uploadArea.classList.remove('dragover');
            
            const files = e.dataTransfer.files;
            if (files.length > 0 && files[0].type.startsWith('video/')) {
                const fileInput = document.getElementById('video-file');
                fileInput.files = files;
                handleFileUpload({ target: fileInput });
            }
        });
    
        // Initialize
        document.addEventListener('DOMContentLoaded', () => {
            console.log('LipNet Web Application Loaded');
            showStatus('live-status', 'System ready for demonstration', 'processing');
        });
    </script>
</body>
</html>